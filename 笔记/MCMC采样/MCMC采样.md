# MCMC采样

##推断inference：

​	什么是推断，给出一堆数据，它的分布根隐变量有关，记隐变量为z，给出z的先验分布，以此来得到z的后验分布 $P(Z|X)$ ，这个过程就是推断

## 蒙特卡罗方法Monte Carlo Method:

​	首先说说MCMC采样，MCMC采样是一种近似推断，属于近似推断里的随即推断，里面的一部分就是蒙特卡罗方法。它（蒙特卡罗）实际上就是一种基于采样的随机近似方法，主要用来求积分，或者期望

​	以期望为例，要求Z的后验分布的期望
$$
E_{z|x}[f(x)] = \int{p(z|x)f(z)dz}
			  \approx\frac{1}{N}\sum_{i=1}^{n}f(z_{i})
$$
​	先来解释这个公式是什么意思，中间是求数学期望的公式，没什么好说的，后面直观理解，积分本质是一种求和。 $p(z|x)$的积分是1(概率密度)所以，1/N可以理解为均值，及矩形框的宽，那么 $f(z_{i})$ 就是小矩形的长了。![v2-f651c32480a979828d078a52bb312765_720w](C:\Users\asus\Desktop\学习\实验室CV文章\笔记\MCMC采样\图\v2-f651c32480a979828d078a52bb312765_720w.jpg)

因此，积分就能近似为后面的公式（前提是他是均匀分布，但很显然大多数情况下他不是）。然后，求积分就能变成在原来的 $p(z|x)$ 里去随机采样，通过这些点求得对应的f(z)，直接计算积分。

​	但是，有的时候，有的分布的概率密度非常复杂，这导致我们想要获得完整的分布函数是不可能的（有可能只能计算单个点对应的数值），这个时候就需要另外两种辅助的采样方法。

###拒绝采样Adjection Sampling（又称接受-拒绝采样）：

​	![IMG_20220130_170427](C:\Users\asus\Desktop\学习\实验室CV文章\笔记\MCMC采样\图\IMG_20220130_170427.jpg)

​	拒绝-接受采样的核心其实是一个引入的推荐分布proposal distribution，因为根据上面所说，p(z)的分布函数cdf（又叫累计函数）很难求，因此引入一个非常好求的分布q(z)(本身要和p(z)接近)，并通过引入的q(z)来求得积分。

#### 	要点：

- $q(z)$ 需要乘以一个常数M，这是为了保证Mq(z)始终在p(z)上方，q(z)与p(z)同为概率函数，他们积分一定是1，因此不可能直接找到一个q(z)使得其满足它一定大于等于p(z)
- $\alpha$ 为接收率，如图红色部分，它是一个阈值，当所取得的点在阴影区域以外时舍弃，以内保留，定义为 $\alpha=\frac{P(z_{i})}{Mq(z_{i})}$ ，由图可知，$\alpha$ 所在区间一定为[0,1]

#### 	算法：

1. 引入一个分布q(z)，并确定M
2. 对均匀分布u~U(0,1)进行随机采样，如果 $u\leq\alpha$ ，则接受u所对应的z(用0,1均匀分布的反函数求得z)，反之，拒绝z
3. 得到的一组z即为采样点

​	为何要使用均匀分布，因为对于0,1均匀分布，计算机是非常方便生成随机采样点的，各种random函数随便来

### 重要性采样Importance Sampling:

​	这东西还得从一个公式说起，我们求积分也可以求期望。
$$
E_{p(z)}[f(z)]=\int{p(z)f(z)dz}
				  =\int\frac{p(z)}{q(z)}*q(z)*f(z)dz
				  \approx\frac{1}{N}\sum_{i=1}^{N}f(z_{i})*\frac{p(z_{i})}{q(z_{i})}
$$
​	还是老问题，这个f(x)的完整图像太难求了，因此引入一个推荐分布q(z)，然后注意看最后一个公式，如何理解   
$$
\frac{1}{N}\sum_{i=1}^{N}f(z_{i})*\frac{p(z_{i})}{q(z_{i})}
$$
​	本质上 $\frac{p(z_{i})}{q(z_{i})}$ 是一个权重，之前上文提到过，很多函数的分布都不是均匀分布，因此小矩形的宽度并不是 $\frac{1}{N}$ ，这个时候在这宽度上乘以一个权重$\frac{p(z_{i})}{q(z_{i})}$  ，就能最大的近似原函数的积分，也就是z的后验概率的期望值 $E_{p(z)}[f(z)]$ 。

​	那么我们就可以找这样的一系列的点，上述权重最接近1的点，找到对应的z，并在q(z)中采样，估计p(z)的期望，就是重要性采样。

## 马尔科夫链Markov Chain（马氏链）：

​	马尔科夫链是一组时间和状态都是离散的随机变量序列

​	马氏链的精确数学定义：

​		假设我们的序列状态是 $...X_{t-2},X_{t-1},X_{t},X_{t+1},...$ ,那么我们在 $X_{t+1}$ 时刻的条件概率仅仅依赖于时刻 $X_{t}$​ ，即：
$$
P(X_{t+1}|...X_{t-2},X_{t-1},X_{t})=P(X_{t+1}|X_{t})
$$

### 平稳分布：

​	首先要了解状态转移矩阵，状态转移矩阵就是P，里面单独的$P_{ij}$ 就是从状态i转移到状态j的概率，马氏链的每一个状态节点都是一组随机变量序列，他们遵循一定的状态分布，前一个随机变量序列乘以对应的状态转移矩阵，就可以算出下一个状态的随机变量序列。

​	那什么是平稳分布呢，当以下公式 
$$
\pi(x^{*})=\int\pi(x)*p(x\rightarrow x^{*})dx
$$
满足时，整个马氏链就达到了平稳分布。

### Detailed Balance细致平衡:

​	Detailed Balance是马氏链达到平稳分布的充分条件，但不是必要的，此条件为：
$$
\pi(x)*p(x\rightarrow x^{*})=\pi(x^{*})*p(x^{*}\rightarrow x)
$$
为何是充分条件，证明过程
$$
\pi(x^{*})=\int\pi(x)*p(x\rightarrow x^{*})dx
		  =\int\pi(x^{*})p(x^{*}\rightarrow x)dx
		  =\pi(x^{*})\int p(x^{*}\rightarrow x)dx
		  =\pi(x^{*})
$$
状态转移矩阵相当于概率密度矩阵，所以对其求积分，相当于矩阵求矩阵一行的和，求和结果为1，即$\int p(x^{*}\rightarrow x)dx$ 结果为1。

### 总结：

​	当马氏链的每个状态对应的随机变量分布乘以状态转移矩阵不在变化，则达到了平稳分布。

## M-H采样Metropolis-Hastings：

### 状态转移矩阵的推导：

​	我们要求p(z)的分布，那么我们首先要构造一个逼近p(z)的马氏链，最大的问题就是如何求出让马氏链达到平稳分布的状态转移矩阵？看如下公式：
$$
要满足条件\\
p(z)Q(z\rightarrow z^{*})=p(z^{*})Q(z^{*}\rightarrow z)\\
两边同时乘以一个参数\\
p(z)Q(z\rightarrow z^{*})\alpha(z,z^{*})=p(z^{*})Q(z^{*}\rightarrow z)\alpha(z^{*},z)\\
\alpha(z,z^{*}) = min \{1,\frac{p(z^{*})Q(z^{*}\rightarrow z)}{p(z)Q(z\rightarrow z^{*})}\}
$$
​	为什么取这样一个参数呢，这个参数为什么能满足细致平稳条件？
$$
p(z)Q(z\rightarrow z^{*})\alpha(z,z^{*})=p(z)Q(z\rightarrow z^{*})*min \{1,\frac{p(z^{*})Q(z^{*}\rightarrow z)}{p(z)Q(z\rightarrow z^{*})}\}
\\=min\{p(z)Q(z\rightarrow z^{*}),p(z^{*})Q(z^{*}\rightarrow z)\}
\\=p(z^{*})Q(z^{*}\rightarrow z)*min\{1,\frac{p(z)Q(z\rightarrow z^{*})}{p(z^{*})Q(z^{*}\rightarrow z)}\}
\\可以很容易看到min\{1,\frac{p(z)Q(z\rightarrow z^{*})}{p(z^{*})Q(z^{*}\rightarrow z)}\}就是\alpha(z^{*},z)
$$
这样就证明了这个$\alpha$ 参数的正确性，我们把这个参数称为接收率。

### 具体算法：

1. u~U(0,1)现在均匀分布力作随机采样
2. $z^{*}\sim Q(z|z^{i-1})$ 
3. $\alpha=min\{1,\frac{p(z^{*})Q(z^{*}\rightarrow z)}{p(z)Q(z\rightarrow z^{*})}\}$
4. 如果此时$u\leq\alpha$ ,则接受采取到的样本$z^{*}作为z^{i}$
5. 如果不满足，则将原来的$z^{i-1}$作为第i个样本$z^i$ 

​	然后重复这个过程n次，就能拿到一系列的样本点，由于这个马氏链最后是逼近p(z)这个分布的(因为状态转移再怎么转都是固定的p(z)了)，因此他最后产生的就是在p(x)的分布函数上取样的样本点，再把这一堆样本点丢到蒙特卡罗方法里面去，在那里把后验分布的期望值求出来，就能求出整个分布函数的积分了。

## 吉布斯采样GIBBS：

​	首先定个性，吉布斯采样就是一种特殊的MH采样，此MH采样的接受率为1。

​	吉布斯采样一个最巧妙的点就在于他的状态转移矩阵是用条件概率分布直接充当的，最终导致了其接收率为1。

### 大致描述：

​	吉布斯采样是专门针对于高维度分布的采样。它是一维一维的采样的，在最后把采样的每个维度拼接，就成了一个采样点。注意：**他只对高维有效，维度必须$\ge2$** 

### 证明：

​	下面来证明为什么吉布斯采样是接收率为1的MH采样。

​	首先来回顾MH采样的接受率：
$$
\alpha=min\{1,\frac{p(z^{*})Q(z^{*}\rightarrow z)}{p(z)Q(z\rightarrow z^{*})}\}
$$
然后套用吉布斯采样的定义，用条件概率代替状态转移矩阵。
$$
\frac{p(z^{*})Q(z^{*}\rightarrow z)}{p(z)Q(z\rightarrow z^{*})}=\frac{p(z_i^*|z_{-i}^*)p(z_{-i}^*)*p(z_i|z_{-i}^*)}{p(z_i|z_{-i})p(z_{-i})*p(z_i^*|z_{-i})}
$$
对这个公式做出一些解释：

- 首先要解释什么是$p(z_{-i})$ ,对第i个维度采样求他的分布就是$p(z_i)$ ，$z_{-i}$ 就是这个联合分布中除i维度以外其他所有的维度，那么$p(z_{-i})$ 就相当于是一种边缘概率了。

- $p(z^*)=p(z_i^*|z_{-i}^*)p(z_{-i}^*)$ 这其实就是联合概率分布，用二维分布举例，$f(x,y) = f(x|y)*f(y)$ 因为根据条件概率的公式$f(x|y)=\frac{f(x,y)}{f(y)}$ ,对于分母同理

- 定义说用条件概率代替状态转移矩阵(就不用我们自己找状态转移矩阵了)，此条件概率就是$p(z_i|z_{-i}^*)$ 

- 这个$z^*和z$ 的关系，举例说明：

  假设现有一个联合分布$p(z_1,z_2,z_3)$ ，我们对维度1进行采样

  ​				在t=1时刻，我们对维度1进行采样

  ​				t=1，$(z_1^{(1)},z_2^{(1)},z_3^{(1)})$ 

  ​				t=2，$(z_1^{(2)},z_2^{(1)},z_3^{(1)})$ 

  这个时候我们注意到，我们始终是对维度1进行采样，变量始终是$z_1$ 而$z_2,z_3$ 始终是不变的，这句话的意思其实已经很明了了，对应过来就是，当对一个确定的维度进行采样的时候，在变化的只有$z_i$ 而$z_{-i}$ 始终是不变的，因此 $z_{-i} = z_{-i}^*$ 始终成立

那么我们就可以对上述式子进行化简了，由于$z_{-i} = z_{-i}^*$ ,因此$p(z_{-i})=p(z_{-i}^*)$ 原式可化为：
$$
\frac{p(z_i^*|z_{-i}^*)p(z_{-i}^*)*p(z_i|z_{-i}^*)}{p(z_i|z_{-i})p(z_{-i})*p(z_i^*|z_{-i})}=\frac{p(z_i^*|z_{-i})p(z_{-i})*p(z_i|z_{-i})}{p(z_i|z_{-i})p(z_{-i})*p(z_i^*|z_{-i})}
\\=1
$$
 接收率就惊人的为1了，真他妈神奇。

### 具体采样方法：

​	一般吉布斯采样都做坐标轮换采样法，以二维举例

1. 输入平稳分布$p(x_1,x_2)$

2. 随机初始化状态值$x_1^{(0)},x_2^{(0)}$

3. 循环以下操作：

   - 从条件概率分布$p(x_2,x_1^{(t)})$中采的样本$X_2^{t+1}$
   - 从条件概率分布$p(x_1,x_2^{(t+1)})$中采的样本$x_1^{t+1}$

4. 然后收集到足够的样本集
   $$
   (x_1^{(1)},x_2^{(1)})\rightarrow(x_1^{(2)},x_2^{(2)})\rightarrow(x_1^{(3)},x_2^{(3)})\rightarrow...\rightarrow(x_1^{(n)},x_2^{(n)})
   $$
   注：坐标轮换不是必须的，也可以每次随机抽取一个维度采样，但是切记不能死得着一个维度采，容易特殊化。

### 最后附上证明GIBBS采样满足细致平稳条件的证明：

![IMG_20220203_195444](C:\Users\asus\Desktop\学习\实验室CV文章\笔记\截图\IMG_20220203_195444.jpg)
